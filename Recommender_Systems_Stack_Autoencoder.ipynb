{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_T6DwmhLeEU"
      },
      "source": [
        "# AutoEncoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRfllOFCeNIe"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVdzTkqHehem"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncWa_a4Zek9k"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvcjT5Uqeqrj"
      },
      "source": [
        "movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxJyeJVSeuYF"
      },
      "source": [
        "## Preparing the training set and the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXy3oK_5e26x"
      },
      "source": [
        "training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t')\n",
        "training_set = np.array(training_set, dtype = 'int')\n",
        "test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')\n",
        "test_set = np.array(test_set, dtype = 'int')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6AZsqV0fBth"
      },
      "source": [
        "## Getting the number of users and movies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjYBgQJ4fHXp"
      },
      "source": [
        "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
        "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BduAm9XTfJ5M"
      },
      "source": [
        "## Converting the data into an array with users in lines and movies in columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hvNwdPwfNJa"
      },
      "source": [
        "def convert(data):\n",
        "    new_data = []\n",
        "    for id_users in range(1, nb_users + 1):\n",
        "        id_movies = data[:,1][data[:,0] == id_users]\n",
        "        id_ratings = data[:,2][data[:,0] == id_users]\n",
        "        ratings = np.zeros(nb_movies)\n",
        "        ratings[id_movies - 1] = id_ratings\n",
        "        new_data.append(list(ratings))\n",
        "    return new_data\n",
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDMTdRohfca9"
      },
      "source": [
        "## Converting the data into Torch tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCrtcCCqfgNc"
      },
      "source": [
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68DIciQ1fifc"
      },
      "source": [
        "## Creating the architecture of the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3JKRMIXfmTr"
      },
      "source": [
        "class SAE(nn.Module):\n",
        "    def __init__(self, ):\n",
        "        super(SAE, self).__init__()\n",
        "        self.fc1 = nn.Linear(nb_movies, 20)\n",
        "        self.fc2 = nn.Linear(20, 10)\n",
        "        self.fc3 = nn.Linear(10, 20)\n",
        "        self.fc4 = nn.Linear(20, nb_movies)\n",
        "        self.activation = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.activation(self.fc2(x))\n",
        "        x = self.activation(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "sae = SAE()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn8Zl34Ofpe_"
      },
      "source": [
        "## Training the SAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89ACdnopfwrG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83b4d0b7-9c0d-4c7a-f87b-39efdfc55ae0",
        "collapsed": true
      },
      "source": [
        "nb_epoch = 200\n",
        "for epoch in range(1, nb_epoch + 1):\n",
        "    train_loss = 0\n",
        "    s = 0.\n",
        "    for id_user in range(nb_users):\n",
        "        input = Variable(training_set[id_user]).unsqueeze(0)\n",
        "        target = input.clone()\n",
        "        if torch.sum(target.data > 0) > 0:\n",
        "            output = sae(input)\n",
        "            target.require_grad = False\n",
        "            output[target == 0] = 0\n",
        "            loss = criterion(output, target)\n",
        "            mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
        "            loss.backward()\n",
        "            train_loss += np.sqrt(loss.item()*mean_corrector)\n",
        "            s += 1.\n",
        "            optimizer.step()\n",
        "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 loss: 0.9122962864609544\n",
            "epoch: 2 loss: 0.9124135945514019\n",
            "epoch: 3 loss: 0.9124813657254329\n",
            "epoch: 4 loss: 0.9120147371911713\n",
            "epoch: 5 loss: 0.9119967411464017\n",
            "epoch: 6 loss: 0.9116074472495177\n",
            "epoch: 7 loss: 0.9117959214113336\n",
            "epoch: 8 loss: 0.911300088247584\n",
            "epoch: 9 loss: 0.9110865742452618\n",
            "epoch: 10 loss: 0.9107010225890773\n",
            "epoch: 11 loss: 0.9110042379495668\n",
            "epoch: 12 loss: 0.9103630650769328\n",
            "epoch: 13 loss: 0.9105526727581045\n",
            "epoch: 14 loss: 0.9096652587664943\n",
            "epoch: 15 loss: 0.9100089349689517\n",
            "epoch: 16 loss: 0.9093712295506277\n",
            "epoch: 17 loss: 0.9092595420089462\n",
            "epoch: 18 loss: 0.9089413490727202\n",
            "epoch: 19 loss: 0.908944464885167\n",
            "epoch: 20 loss: 0.90857142125581\n",
            "epoch: 21 loss: 0.9083663593766105\n",
            "epoch: 22 loss: 0.9080955844324617\n",
            "epoch: 23 loss: 0.9077873952699266\n",
            "epoch: 24 loss: 0.9071130110661838\n",
            "epoch: 25 loss: 0.9073809633910013\n",
            "epoch: 26 loss: 0.9068681352492772\n",
            "epoch: 27 loss: 0.907206611227186\n",
            "epoch: 28 loss: 0.9065351236010926\n",
            "epoch: 29 loss: 0.9071377399104554\n",
            "epoch: 30 loss: 0.9071371585543726\n",
            "epoch: 31 loss: 0.9062658285423549\n",
            "epoch: 32 loss: 0.905863178377648\n",
            "epoch: 33 loss: 0.905739285170473\n",
            "epoch: 34 loss: 0.9050059789387738\n",
            "epoch: 35 loss: 0.9048749643875423\n",
            "epoch: 36 loss: 0.9046815882922022\n",
            "epoch: 37 loss: 0.9049860069835656\n",
            "epoch: 38 loss: 0.9047538844761338\n",
            "epoch: 39 loss: 0.9035727360538239\n",
            "epoch: 40 loss: 0.9033427628225256\n",
            "epoch: 41 loss: 0.902943492861608\n",
            "epoch: 42 loss: 0.9017062887148599\n",
            "epoch: 43 loss: 0.9016722371023479\n",
            "epoch: 44 loss: 0.9018527024168945\n",
            "epoch: 45 loss: 0.9014184981395338\n",
            "epoch: 46 loss: 0.9002056093729173\n",
            "epoch: 47 loss: 0.8992580208921962\n",
            "epoch: 48 loss: 0.8991713345069278\n",
            "epoch: 49 loss: 0.8990698486898951\n",
            "epoch: 50 loss: 0.8982468623810025\n",
            "epoch: 51 loss: 0.898794992347595\n",
            "epoch: 52 loss: 0.8992132315065615\n",
            "epoch: 53 loss: 0.896975945272947\n",
            "epoch: 54 loss: 0.8962082345743051\n",
            "epoch: 55 loss: 0.8957892052499316\n",
            "epoch: 56 loss: 0.8957540125478607\n",
            "epoch: 57 loss: 0.8950594128079744\n",
            "epoch: 58 loss: 0.8942385410504943\n",
            "epoch: 59 loss: 0.893943409678942\n",
            "epoch: 60 loss: 0.8932707877524585\n",
            "epoch: 61 loss: 0.8927413063952186\n",
            "epoch: 62 loss: 0.8925036878393748\n",
            "epoch: 63 loss: 0.8923712007375738\n",
            "epoch: 64 loss: 0.8921313882353651\n",
            "epoch: 65 loss: 0.8913471136607028\n",
            "epoch: 66 loss: 0.8907726949685663\n",
            "epoch: 67 loss: 0.8903333565738529\n",
            "epoch: 68 loss: 0.8901932789171283\n",
            "epoch: 69 loss: 0.8897927778517909\n",
            "epoch: 70 loss: 0.8898299965052313\n",
            "epoch: 71 loss: 0.8888547347755618\n",
            "epoch: 72 loss: 0.8887501759921511\n",
            "epoch: 73 loss: 0.8885708636003448\n",
            "epoch: 74 loss: 0.8876195628102538\n",
            "epoch: 75 loss: 0.887476730231771\n",
            "epoch: 76 loss: 0.8866967150514432\n",
            "epoch: 77 loss: 0.8864196508328687\n",
            "epoch: 78 loss: 0.8867921263790342\n",
            "epoch: 79 loss: 0.8864999854091917\n",
            "epoch: 80 loss: 0.8858127122639364\n",
            "epoch: 81 loss: 0.885162369426115\n",
            "epoch: 82 loss: 0.8852300444197002\n",
            "epoch: 83 loss: 0.8846342615232952\n",
            "epoch: 84 loss: 0.8848200830635434\n",
            "epoch: 85 loss: 0.8848814139664303\n",
            "epoch: 86 loss: 0.8838210415250071\n",
            "epoch: 87 loss: 0.8836336654114646\n",
            "epoch: 88 loss: 0.8830712971968897\n",
            "epoch: 89 loss: 0.8824934646978247\n",
            "epoch: 90 loss: 0.8829400455311337\n",
            "epoch: 91 loss: 0.8821749925037645\n",
            "epoch: 92 loss: 0.8820291490675146\n",
            "epoch: 93 loss: 0.8815117076855296\n",
            "epoch: 94 loss: 0.8818013547967137\n",
            "epoch: 95 loss: 0.880864438516115\n",
            "epoch: 96 loss: 0.8805337224648114\n",
            "epoch: 97 loss: 0.8801788723718661\n",
            "epoch: 98 loss: 0.8799225800302801\n",
            "epoch: 99 loss: 0.8797355507322303\n",
            "epoch: 100 loss: 0.8798989188228475\n",
            "epoch: 101 loss: 0.8791820828530243\n",
            "epoch: 102 loss: 0.8793124203674191\n",
            "epoch: 103 loss: 0.8792539250441295\n",
            "epoch: 104 loss: 0.8784044892409009\n",
            "epoch: 105 loss: 0.8781331824547617\n",
            "epoch: 106 loss: 0.8783661095957234\n",
            "epoch: 107 loss: 0.877710949611293\n",
            "epoch: 108 loss: 0.8771274074889915\n",
            "epoch: 109 loss: 0.8765351086783711\n",
            "epoch: 110 loss: 0.8768876701916416\n",
            "epoch: 111 loss: 0.8767140020598158\n",
            "epoch: 112 loss: 0.8766266946703576\n",
            "epoch: 113 loss: 0.8763710321749715\n",
            "epoch: 114 loss: 0.8761064622092365\n",
            "epoch: 115 loss: 0.8767690872528704\n",
            "epoch: 116 loss: 0.8774723701746179\n",
            "epoch: 117 loss: 0.8763774442335504\n",
            "epoch: 118 loss: 0.8753796535730821\n",
            "epoch: 119 loss: 0.8748631783053913\n",
            "epoch: 120 loss: 0.8747253734237572\n",
            "epoch: 121 loss: 0.8750581941133115\n",
            "epoch: 122 loss: 0.8742721499786253\n",
            "epoch: 123 loss: 0.8746279951279933\n",
            "epoch: 124 loss: 0.8742680605370642\n",
            "epoch: 125 loss: 0.8736116825962762\n",
            "epoch: 126 loss: 0.8732266857738893\n",
            "epoch: 127 loss: 0.8729794560006798\n",
            "epoch: 128 loss: 0.8732035881358843\n",
            "epoch: 129 loss: 0.8730087235778488\n",
            "epoch: 130 loss: 0.8724815449740755\n",
            "epoch: 131 loss: 0.8720543610211106\n",
            "epoch: 132 loss: 0.8715107558771279\n",
            "epoch: 133 loss: 0.871860806503492\n",
            "epoch: 134 loss: 0.8717484480010856\n",
            "epoch: 135 loss: 0.870783984179602\n",
            "epoch: 136 loss: 0.8711375165839774\n",
            "epoch: 137 loss: 0.8706028964791429\n",
            "epoch: 138 loss: 0.8703030414001256\n",
            "epoch: 139 loss: 0.8701780566369735\n",
            "epoch: 140 loss: 0.8709639926880723\n",
            "epoch: 141 loss: 0.8700860234828697\n",
            "epoch: 142 loss: 0.869199862998844\n",
            "epoch: 143 loss: 0.8691102304552313\n",
            "epoch: 144 loss: 0.868990154047511\n",
            "epoch: 145 loss: 0.8685734465549448\n",
            "epoch: 146 loss: 0.8685946997010627\n",
            "epoch: 147 loss: 0.8680391481456261\n",
            "epoch: 148 loss: 0.8680986958312393\n",
            "epoch: 149 loss: 0.8677523466432236\n",
            "epoch: 150 loss: 0.8675674808222243\n",
            "epoch: 151 loss: 0.8669425164390874\n",
            "epoch: 152 loss: 0.8665327345305713\n",
            "epoch: 153 loss: 0.8664959854166118\n",
            "epoch: 154 loss: 0.8661532572605576\n",
            "epoch: 155 loss: 0.8661434691342313\n",
            "epoch: 156 loss: 0.865808306036018\n",
            "epoch: 157 loss: 0.8654788782970407\n",
            "epoch: 158 loss: 0.8653223018384124\n",
            "epoch: 159 loss: 0.8653320660404784\n",
            "epoch: 160 loss: 0.8649409511632563\n",
            "epoch: 161 loss: 0.8647837623785345\n",
            "epoch: 162 loss: 0.8645688320162592\n",
            "epoch: 163 loss: 0.8641097649149174\n",
            "epoch: 164 loss: 0.8641151810319275\n",
            "epoch: 165 loss: 0.8640723021956223\n",
            "epoch: 166 loss: 0.8638345742604077\n",
            "epoch: 167 loss: 0.8634514117875367\n",
            "epoch: 168 loss: 0.8630438255044818\n",
            "epoch: 169 loss: 0.8630996133829039\n",
            "epoch: 170 loss: 0.862758847262679\n",
            "epoch: 171 loss: 0.8623038674919046\n",
            "epoch: 172 loss: 0.8621274822277192\n",
            "epoch: 173 loss: 0.8618127655315115\n",
            "epoch: 174 loss: 0.8615945434908325\n",
            "epoch: 175 loss: 0.8612481835538017\n",
            "epoch: 176 loss: 0.8611455939841844\n",
            "epoch: 177 loss: 0.8603842167741609\n",
            "epoch: 178 loss: 0.8605446888550201\n",
            "epoch: 179 loss: 0.8605663174809502\n",
            "epoch: 180 loss: 0.8604122396943099\n",
            "epoch: 181 loss: 0.8593311905666705\n",
            "epoch: 182 loss: 0.859857527244907\n",
            "epoch: 183 loss: 0.859434776401905\n",
            "epoch: 184 loss: 0.8598805074070229\n",
            "epoch: 185 loss: 0.8589976890788756\n",
            "epoch: 186 loss: 0.8594645134164179\n",
            "epoch: 187 loss: 0.8585902539138145\n",
            "epoch: 188 loss: 0.8589298014262094\n",
            "epoch: 189 loss: 0.8580242071020732\n",
            "epoch: 190 loss: 0.8580599298613943\n",
            "epoch: 191 loss: 0.8580173475812493\n",
            "epoch: 192 loss: 0.8579728630740101\n",
            "epoch: 193 loss: 0.8574006684942833\n",
            "epoch: 194 loss: 0.8571211386637395\n",
            "epoch: 195 loss: 0.8569652019949104\n",
            "epoch: 196 loss: 0.8568149805378723\n",
            "epoch: 197 loss: 0.8566732099157076\n",
            "epoch: 198 loss: 0.8566176121589663\n",
            "epoch: 199 loss: 0.8560106993497045\n",
            "epoch: 200 loss: 0.8564074752795342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYTV81Yif0Sc"
      },
      "source": [
        "## Testing the SAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5_mJJscf3oj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d9be9fb-2d7e-4ae9-a371-7dca97bdffde"
      },
      "source": [
        "test_loss = 0\n",
        "s = 0.\n",
        "for id_user in range(nb_users):\n",
        "    input = Variable(training_set[id_user]).unsqueeze(0)\n",
        "    target = Variable(test_set[id_user]).unsqueeze(0)\n",
        "    if torch.sum(target.data > 0) > 0:\n",
        "        output = sae(input)\n",
        "        target.require_grad = False\n",
        "        output[target == 0] = 0\n",
        "        loss = criterion(output, target)\n",
        "        mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
        "        test_loss += np.sqrt(loss.data*mean_corrector)\n",
        "        s += 1.\n",
        "print('test loss: '+str(test_loss/s))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: tensor(0.9588)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_user_recommendation = 0\n",
        "\n",
        "# Prepare the input for the selected user\n",
        "input_recommendation = Variable(training_set[id_user_recommendation]).unsqueeze(0) # or torch.Tensor if not using Variable\n",
        "# or if not using Variable: input_recommendation = training_set[id_user_recommendation].unsqueeze(0)\n",
        "\n",
        "\n",
        "# Get the predicted ratings from the trained SAE\n",
        "output_recommendation = sae(input_recommendation) # or sae(input_recommendation) if not using Variable\n",
        "predicted_ratings = output_recommendation.data.numpy()[0] # or output_recommendation.detach().numpy()[0] if not using Variable\n",
        "\n",
        "\n",
        "# Mask movies already rated by the user (set predicted rating to a very small value)\n",
        "rated_movies_mask = training_set[id_user_recommendation].numpy() > 0 # or training_set[id_user_recommendation].numpy() > 0 if not using Variable\n",
        "predicted_ratings[rated_movies_mask] = -np.inf  # Mask already rated movies\n",
        "\n",
        "\n",
        "# Get the indices of movies with the highest predicted ratings (recommend top 10 movies)\n",
        "top_n = 10\n",
        "recommended_movie_indices = np.argsort(predicted_ratings)[::-1][0:top_n]\n",
        "\n",
        "print(\"Recommendations for user\", id_user_recommendation)\n",
        "for movie_index in recommended_movie_indices:\n",
        "    print(f\"Movie Index: {movie_index}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAli8c6wxY3a",
        "outputId": "83ba5f93-3a26-42a8-c459-ec747d4a1cd0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for user 0\n",
            "Movie Index: 1499\n",
            "Movie Index: 1598\n",
            "Movie Index: 1641\n",
            "Movie Index: 1448\n",
            "Movie Index: 407\n",
            "Movie Index: 1466\n",
            "Movie Index: 1652\n",
            "Movie Index: 850\n",
            "Movie Index: 1638\n",
            "Movie Index: 1366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5to6SKuLM_Q-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}